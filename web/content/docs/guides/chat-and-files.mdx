---
title: Chat and Files
description: High-signal file-aware chat workflows for reliable coding outcomes.
---

# Chat and Files

This guide focuses on getting reliable outcomes from file-aware chat workflows.

## Why File Context Discipline Matters

Agent output quality depends on context precision.

Best practice:

- reference exact files
- keep prompts bounded
- validate outputs against expected files

## Recommended Workflow

1. Open target workspace in Explorer.
2. Use Search to locate exact files.
3. Reference files in chat with `@` mentions.
4. Send a narrow task prompt.
5. Validate changes in file/diff panels.

For non-text updates:

- image proposals support side-by-side diff review plus apply/discard in Editor
- PDF proposals support staged text diff review when payload includes `dataUrl`,
  `currentText`, and `proposedText`
- unsupported audio/video/office binary types show explicit fallback guidance

Example PDF proposal payload:

```json
{
  "dataUrl": "data:application/pdf;base64,...",
  "currentText": "Extracted text from current PDF",
  "proposedText": "Extracted text from proposed PDF"
}
```

## Prompt Pattern For File Work

Use this structure:

1. objective
2. files in scope
3. constraints
4. expected output

Example:

"Update `src/main/todo-runner.ts` to improve error reporting for blocked items. Do not change retry semantics. Return a short summary and list edited files."

## Image-Aided Debugging

For UI issues:

1. paste screenshot directly in chat
2. reference affected file paths
3. request a fix plus visual verification steps

This is much more reliable than purely textual bug reports.

## Verification Checklist

After each run:

1. Confirm only expected files changed.
2. Confirm output summary matches actual edits.
3. Run relevant checks/tests.
4. Capture any residual errors before next run.

## Common Pitfalls

- broad prompts across many files
- missing file references for critical changes
- skipping post-change verification
- relying on implicit repository context

## Recovery Pattern

If result quality drops:

1. reduce scope to one file/task
2. restate constraints explicitly
3. rerun with concrete success criteria
4. scale back up once stable
